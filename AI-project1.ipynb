{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Requirements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-17T18:49:41.822313Z",
     "iopub.status.busy": "2025-03-17T18:49:41.821826Z",
     "iopub.status.idle": "2025-03-17T18:49:43.640608Z",
     "shell.execute_reply": "2025-03-17T18:49:43.639662Z",
     "shell.execute_reply.started": "2025-03-17T18:49:41.822280Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from pydub import AudioSegment\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, average_precision_score, f1_score, precision_score, recall_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Change the format of the input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T18:49:04.816033Z",
     "iopub.status.busy": "2025-03-17T18:49:04.815509Z",
     "iopub.status.idle": "2025-03-17T18:49:06.780883Z",
     "shell.execute_reply": "2025-03-17T18:49:06.779509Z",
     "shell.execute_reply.started": "2025-03-17T18:49:04.815972Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!git clone --depth 1 --filter=blob:none --sparse https://github.com/liucht4212/AI_project1.git\n",
    "!cd AI_project1 && git sparse-checkout set voiced voiceless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T18:49:44.285049Z",
     "iopub.status.busy": "2025-03-17T18:49:44.284507Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_folder = \"AI_project1\"\n",
    "output_folder = \"processed_dataset\"\n",
    "\n",
    "for category in [\"voiced\", \"voiceless\"]:\n",
    "    os.makedirs(f\"{output_folder}/{category}\", exist_ok=True)\n",
    "    for file in os.listdir(f\"{input_folder}/{category}\"):\n",
    "        if file.endswith(\".mp3\"):\n",
    "            audio = AudioSegment.from_mp3(f\"{input_folder}/{category}/{file}\")\n",
    "            audio = audio.set_frame_rate(16000).set_channels(1)  \n",
    "            audio.export(f\"{output_folder}/{category}/{file.replace('.mp3', '.wav')}\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T17:06:34.734022Z",
     "iopub.status.busy": "2025-03-17T17:06:34.733618Z",
     "iopub.status.idle": "2025-03-17T17:06:56.242444Z",
     "shell.execute_reply": "2025-03-17T17:06:56.241386Z",
     "shell.execute_reply.started": "2025-03-17T17:06:34.733981Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_folder = \"processed_dataset\"\n",
    "np.random.seed(42)\n",
    "X_mfcc = []  \n",
    "y_mfcc = []\n",
    "X_zcr = []\n",
    "y_zcr = []\n",
    "X_mel = []\n",
    "y_mel = []\n",
    "X_contrast = []\n",
    "y_contrast = [] \n",
    "\n",
    "for label, category in enumerate([\"voiceless\", \"voiced\"]):\n",
    "    for file in os.listdir(f\"{dataset_folder}/{category}\"):\n",
    "        if file.endswith(\".wav\"):\n",
    "            y, sr = librosa.load(f\"{dataset_folder}/{category}/{file}\", sr=16000)\n",
    "            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "            mfccs_mean = np.mean(mfccs, axis=1) \n",
    "            X_mfcc.append(mfccs_mean)\n",
    "            y_mfcc.append(label)\n",
    "            \n",
    "            zcr = librosa.feature.zero_crossing_rate(y=y)\n",
    "            zcr_mean = np.mean(zcr, axis=1)\n",
    "            X_zcr.append(zcr_mean)\n",
    "            y_zcr.append(label)\n",
    "            \n",
    "            mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=40)\n",
    "            mel_spec_db = librosa.power_to_db(mel_spec)\n",
    "            mel_mean = np.mean(mel_spec_db, axis=1)\n",
    "            X_mel.append(mel_mean)\n",
    "            y_mel.append(label)\n",
    "            \n",
    "\n",
    "X_mfcc = np.array(X_mfcc)\n",
    "y_mfcc = np.array(y_mfcc)\n",
    "X_zcr = np.array(X_zcr)\n",
    "y_zcr = np.array(y_zcr)\n",
    "X_mel = np.array(X_mel)\n",
    "y_mel = np.array(y_mel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Supervised learning-MFCC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T17:06:56.244398Z",
     "iopub.status.busy": "2025-03-17T17:06:56.243797Z",
     "iopub.status.idle": "2025-03-17T17:07:18.341960Z",
     "shell.execute_reply": "2025-03-17T17:07:18.340838Z",
     "shell.execute_reply.started": "2025-03-17T17:06:56.244361Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "svm_model = SVC(kernel=\"linear\", probability=True, random_state=42)\n",
    "metrics = {\"accuracy\": [], \"roc_auc\": [], \"f1\": [],\"precision\": [], \"recall\": []}\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_mfcc, y_mfcc):\n",
    "    X_train, X_test = X_mfcc[train_idx], X_mfcc[test_idx]\n",
    "    y_train, y_test = y_mfcc[train_idx], y_mfcc[test_idx]\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    y_proba = svm_model.predict_proba(X_test)[:, 1]\n",
    "    metrics[\"accuracy\"].append(accuracy_score(y_test, y_pred))\n",
    "    metrics[\"roc_auc\"].append(roc_auc_score(y_test, y_proba))\n",
    "    metrics[\"f1\"].append(f1_score(y_test, y_pred))\n",
    "    metrics[\"precision\"].append(precision_score(y_test, y_pred, zero_division=0))\n",
    "    metrics[\"recall\"].append(recall_score(y_test, y_pred))\n",
    "\n",
    "svm_performance_mfcc = {metric: {\"mean\": np.mean(values), \"std\": np.std(values)} for metric, values in metrics.items()}\n",
    "print(\"===== SVM Cross-Validation Performance =====\")\n",
    "for metric, values in svm_performance_mfcc.items():\n",
    "    print(f\"  {metric.upper()}: {values['mean']:.6f} ± {values['std']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T17:07:18.343058Z",
     "iopub.status.busy": "2025-03-17T17:07:18.342797Z",
     "iopub.status.idle": "2025-03-17T17:07:18.818719Z",
     "shell.execute_reply": "2025-03-17T17:07:18.817519Z",
     "shell.execute_reply.started": "2025-03-17T17:07:18.343034Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rf_model = RandomForestClassifier(n_estimators=45, max_depth=5, random_state=42)\n",
    "metrics = {\"accuracy\": [], \"roc_auc\": [], \"f1\": [],\"precision\": [], \"recall\": []}\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_mfcc, y_mfcc):\n",
    "    X_train, X_test = X_mfcc[train_idx], X_mfcc[test_idx]\n",
    "    y_train, y_test = y_mfcc[train_idx], y_mfcc[test_idx]\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    y_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "    metrics[\"accuracy\"].append(accuracy_score(y_test, y_pred))\n",
    "    metrics[\"roc_auc\"].append(roc_auc_score(y_test, y_proba))\n",
    "    metrics[\"f1\"].append(f1_score(y_test, y_pred))\n",
    "    metrics[\"precision\"].append(precision_score(y_test, y_pred, zero_division=0))\n",
    "    metrics[\"recall\"].append(recall_score(y_test, y_pred))\n",
    "\n",
    "rf_performance_mfcc = {metric: {\"mean\": np.mean(values), \"std\": np.std(values)} for metric, values in metrics.items()}\n",
    "print(\"===== Random Forest Performance =====\")\n",
    "for metric, values in rf_performance_mfcc.items():\n",
    "    print(f\"  {metric.upper()}: {values['mean']:.6f} ± {values['std']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T17:07:18.820163Z",
     "iopub.status.busy": "2025-03-17T17:07:18.819747Z",
     "iopub.status.idle": "2025-03-17T17:07:19.143323Z",
     "shell.execute_reply": "2025-03-17T17:07:19.142011Z",
     "shell.execute_reply.started": "2025-03-17T17:07:18.820134Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#comparison with two model\n",
    "metrics = [\"accuracy\", \"roc_auc\", \"f1\", \"precision\", \"recall\"]\n",
    "features = [\"SVM\", \"Random Forest\"]\n",
    "\n",
    "means = np.array([\n",
    "    [svm_performance_mfcc[m][\"mean\"] for m in metrics],\n",
    "    [rf_performance_mfcc[m][\"mean\"] for m in metrics],\n",
    "])\n",
    "stds = np.array([\n",
    "    [svm_performance_mfcc[m][\"std\"] for m in metrics],\n",
    "    [rf_performance_mfcc[m][\"std\"] for m in metrics],\n",
    "])\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.25\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for i in range(len(features)):\n",
    "    ax.bar(x + i * width, means[i], width, label=features[i], yerr=stds[i], capsize=5)\n",
    "\n",
    "ax.set_xlabel(\"Metrics\")\n",
    "ax.set_ylabel(\"Performance Score\")\n",
    "ax.set_title(\"Different model Performance Comparison with MFCC\")\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "plt.ylim(0.0, 1.0) \n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Supervised learning-Mel spectrogram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T17:07:19.144605Z",
     "iopub.status.busy": "2025-03-17T17:07:19.144280Z",
     "iopub.status.idle": "2025-03-17T17:07:43.518699Z",
     "shell.execute_reply": "2025-03-17T17:07:43.517421Z",
     "shell.execute_reply.started": "2025-03-17T17:07:19.144578Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "svm_model = SVC(kernel=\"linear\", probability=True, random_state=42)\n",
    "metrics = {\"accuracy\": [], \"roc_auc\": [], \"f1\": [],\"precision\": [], \"recall\": []}\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_mel, y_mel):\n",
    "    X_train, X_test = X_mel[train_idx], X_mel[test_idx]\n",
    "    y_train, y_test = y_mel[train_idx], y_mel[test_idx]\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    y_proba = svm_model.predict_proba(X_test)[:, 1]\n",
    "    metrics[\"accuracy\"].append(accuracy_score(y_test, y_pred))\n",
    "    metrics[\"roc_auc\"].append(roc_auc_score(y_test, y_proba))\n",
    "    metrics[\"f1\"].append(f1_score(y_test, y_pred))\n",
    "    metrics[\"precision\"].append(precision_score(y_test, y_pred, zero_division=0))\n",
    "    metrics[\"recall\"].append(recall_score(y_test, y_pred))\n",
    "\n",
    "svm_performance_mel = {metric: {\"mean\": np.mean(values), \"std\": np.std(values)} for metric, values in metrics.items()}\n",
    "print(\"===== SVM Cross-Validation Performance =====\")\n",
    "for metric, values in svm_performance_mel.items():\n",
    "    print(f\"  {metric.upper()}: {values['mean']:.6f} ± {values['std']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T17:07:43.522517Z",
     "iopub.status.busy": "2025-03-17T17:07:43.522209Z",
     "iopub.status.idle": "2025-03-17T17:07:44.046581Z",
     "shell.execute_reply": "2025-03-17T17:07:44.045507Z",
     "shell.execute_reply.started": "2025-03-17T17:07:43.522493Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rf_model = RandomForestClassifier(n_estimators=45, max_depth=5, random_state=42)\n",
    "metrics = {\"accuracy\": [], \"roc_auc\": [], \"f1\": [],\"precision\": [], \"recall\": []}\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_mel, y_mel):\n",
    "    X_train, X_test = X_mel[train_idx], X_mel[test_idx]\n",
    "    y_train, y_test = y_mel[train_idx], y_mel[test_idx]\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    y_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "    metrics[\"accuracy\"].append(accuracy_score(y_test, y_pred))\n",
    "    metrics[\"roc_auc\"].append(roc_auc_score(y_test, y_proba))\n",
    "    metrics[\"f1\"].append(f1_score(y_test, y_pred))\n",
    "    metrics[\"precision\"].append(precision_score(y_test, y_pred, zero_division=0))\n",
    "    metrics[\"recall\"].append(recall_score(y_test, y_pred))\n",
    "\n",
    "rf_performance_mel = {metric: {\"mean\": np.mean(values), \"std\": np.std(values)} for metric, values in metrics.items()}\n",
    "print(\"===== Random Forest Performance =====\")\n",
    "for metric, values in rf_performance_mel.items():\n",
    "    print(f\"  {metric.upper()}: {values['mean']:.6f} ± {values['std']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T17:07:44.048876Z",
     "iopub.status.busy": "2025-03-17T17:07:44.048486Z",
     "iopub.status.idle": "2025-03-17T17:07:44.295206Z",
     "shell.execute_reply": "2025-03-17T17:07:44.293964Z",
     "shell.execute_reply.started": "2025-03-17T17:07:44.048851Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#comparison with two model\n",
    "metrics = [\"accuracy\", \"roc_auc\", \"f1\", \"precision\", \"recall\"]\n",
    "features = [\"SVM\", \"Random Forest\"]\n",
    "\n",
    "means = np.array([\n",
    "    [svm_performance_mel[m][\"mean\"] for m in metrics],\n",
    "    [rf_performance_mel[m][\"mean\"] for m in metrics],\n",
    "])\n",
    "stds = np.array([\n",
    "    [svm_performance_mel[m][\"std\"] for m in metrics],\n",
    "    [rf_performance_mel[m][\"std\"] for m in metrics],\n",
    "])\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.25\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for i in range(len(features)):\n",
    "    ax.bar(x + i * width, means[i], width, label=features[i], yerr=stds[i], capsize=5)\n",
    "\n",
    "ax.set_xlabel(\"Metrics\")\n",
    "ax.set_ylabel(\"Performance Score\")\n",
    "ax.set_title(\"Different model Performance Comparison with Mel spectrum\")\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "plt.ylim(0.0, 1.0) \n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Supervised learning-Zero crossing rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T17:07:44.296798Z",
     "iopub.status.busy": "2025-03-17T17:07:44.296357Z",
     "iopub.status.idle": "2025-03-17T17:07:44.397673Z",
     "shell.execute_reply": "2025-03-17T17:07:44.396707Z",
     "shell.execute_reply.started": "2025-03-17T17:07:44.296759Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "svm_model = SVC(kernel=\"linear\", probability=True, random_state=42)\n",
    "metrics = {\"accuracy\": [], \"roc_auc\": [], \"f1\": [],\"precision\": [], \"recall\": []}\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_zcr, y_zcr):\n",
    "    X_train, X_test = X_zcr[train_idx], X_zcr[test_idx]\n",
    "    y_train, y_test = y_zcr[train_idx], y_zcr[test_idx]\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    y_proba = svm_model.predict_proba(X_test)[:, 1]\n",
    "    metrics[\"accuracy\"].append(accuracy_score(y_test, y_pred))\n",
    "    metrics[\"roc_auc\"].append(roc_auc_score(y_test, y_proba))\n",
    "    metrics[\"f1\"].append(f1_score(y_test, y_pred))\n",
    "    metrics[\"precision\"].append(precision_score(y_test, y_pred, zero_division=0))\n",
    "    metrics[\"recall\"].append(recall_score(y_test, y_pred))\n",
    "\n",
    "svm_performance_zcr = {metric: {\"mean\": np.mean(values), \"std\": np.std(values)} for metric, values in metrics.items()}\n",
    "print(\"===== SVM Cross-Validation Performance =====\")\n",
    "for metric, values in svm_performance_zcr.items():\n",
    "    print(f\"  {metric.upper()}: {values['mean']:.6f} ± {values['std']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T17:07:44.399111Z",
     "iopub.status.busy": "2025-03-17T17:07:44.398770Z",
     "iopub.status.idle": "2025-03-17T17:07:44.842467Z",
     "shell.execute_reply": "2025-03-17T17:07:44.841275Z",
     "shell.execute_reply.started": "2025-03-17T17:07:44.399084Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rf_model = RandomForestClassifier(n_estimators=45, max_depth=5, random_state=42)\n",
    "metrics = {\"accuracy\": [], \"roc_auc\": [], \"f1\": [],\"precision\": [], \"recall\": []}\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_zcr, y_zcr):\n",
    "    X_train, X_test = X_zcr[train_idx], X_zcr[test_idx]\n",
    "    y_train, y_test = y_zcr[train_idx], y_zcr[test_idx]\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    y_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "    metrics[\"accuracy\"].append(accuracy_score(y_test, y_pred))\n",
    "    metrics[\"roc_auc\"].append(roc_auc_score(y_test, y_proba))\n",
    "    metrics[\"f1\"].append(f1_score(y_test, y_pred))\n",
    "    metrics[\"precision\"].append(precision_score(y_test, y_pred, zero_division=0))\n",
    "    metrics[\"recall\"].append(recall_score(y_test, y_pred))\n",
    "\n",
    "rf_performance_zcr = {metric: {\"mean\": np.mean(values), \"std\": np.std(values)} for metric, values in metrics.items()}\n",
    "print(\"===== Random Forest Performance =====\")\n",
    "for metric, values in rf_performance_zcr.items():\n",
    "    print(f\"  {metric.upper()}: {values['mean']:.6f} ± {values['std']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T17:07:44.844237Z",
     "iopub.status.busy": "2025-03-17T17:07:44.843774Z",
     "iopub.status.idle": "2025-03-17T17:07:45.120917Z",
     "shell.execute_reply": "2025-03-17T17:07:45.119881Z",
     "shell.execute_reply.started": "2025-03-17T17:07:44.844196Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#comparison with two model\n",
    "metrics = [\"accuracy\", \"roc_auc\", \"f1\", \"precision\", \"recall\"]\n",
    "features = [\"SVM\", \"Random Forest\"]\n",
    "\n",
    "means = np.array([\n",
    "    [svm_performance_zcr[m][\"mean\"] for m in metrics],\n",
    "    [rf_performance_zcr[m][\"mean\"] for m in metrics],\n",
    "])\n",
    "stds = np.array([\n",
    "    [svm_performance_zcr[m][\"std\"] for m in metrics],\n",
    "    [rf_performance_zcr[m][\"std\"] for m in metrics],\n",
    "])\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.25\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for i in range(len(features)):\n",
    "    ax.bar(x + i * width, means[i], width, label=features[i], yerr=stds[i], capsize=5)\n",
    "\n",
    "ax.set_xlabel(\"Metrics\")\n",
    "ax.set_ylabel(\"Performance Score\")\n",
    "ax.set_title(\"Different model Performance Comparison with Zero crossing rate\")\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "plt.ylim(0.0, 1.0) \n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Different Feature Extraction comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T17:07:45.122378Z",
     "iopub.status.busy": "2025-03-17T17:07:45.122044Z",
     "iopub.status.idle": "2025-03-17T17:07:45.396775Z",
     "shell.execute_reply": "2025-03-17T17:07:45.395545Z",
     "shell.execute_reply.started": "2025-03-17T17:07:45.122348Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "metrics = [\"accuracy\", \"roc_auc\", \"f1\", \"precision\", \"recall\"]\n",
    "features = [\"MFCC\", \"Mel\", \"ZCR\"]\n",
    "\n",
    "means = np.array([\n",
    "    [svm_performance_mfcc[m][\"mean\"] for m in metrics],\n",
    "    [svm_performance_mel[m][\"mean\"] for m in metrics],\n",
    "    [svm_performance_zcr[m][\"mean\"] for m in metrics],\n",
    "])\n",
    "stds = np.array([\n",
    "    [svm_performance_mfcc[m][\"std\"] for m in metrics],\n",
    "    [svm_performance_mel[m][\"std\"] for m in metrics],\n",
    "    [svm_performance_zcr[m][\"std\"] for m in metrics],\n",
    "])\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.25\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for i in range(len(features)):\n",
    "    ax.bar(x + i * width, means[i], width, label=features[i], yerr=stds[i], capsize=5)\n",
    "\n",
    "ax.set_xlabel(\"Metrics\")\n",
    "ax.set_ylabel(\"Performance Score\")\n",
    "ax.set_title(\"SVM Performance Comparison Across Features\")\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "plt.ylim(0.0, 1.0) \n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T17:07:45.398394Z",
     "iopub.status.busy": "2025-03-17T17:07:45.397961Z",
     "iopub.status.idle": "2025-03-17T17:07:45.670674Z",
     "shell.execute_reply": "2025-03-17T17:07:45.669525Z",
     "shell.execute_reply.started": "2025-03-17T17:07:45.398358Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "metrics = [\"accuracy\", \"roc_auc\", \"f1\", \"precision\", \"recall\"]\n",
    "features = [\"MFCC\", \"Mel\", \"ZCR\"]\n",
    "\n",
    "means = np.array([\n",
    "    [rf_performance_mfcc[m][\"mean\"] for m in metrics],\n",
    "    [rf_performance_mel[m][\"mean\"] for m in metrics],\n",
    "    [rf_performance_zcr[m][\"mean\"] for m in metrics],\n",
    "])\n",
    "stds = np.array([\n",
    "    [rf_performance_mfcc[m][\"std\"] for m in metrics],\n",
    "    [rf_performance_mel[m][\"std\"] for m in metrics],\n",
    "    [rf_performance_zcr[m][\"std\"] for m in metrics],\n",
    "])\n",
    "\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.25\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for i in range(len(features)):\n",
    "    ax.bar(x + i * width, means[i], width, label=features[i], yerr=stds[i], capsize=5)\n",
    "\n",
    "ax.set_xlabel(\"Metrics\")\n",
    "ax.set_ylabel(\"Performance Score\")\n",
    "ax.set_title(\"Random Forest Performance Comparison Across Features\")\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "plt.ylim(0.0, 1.0) \n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Experiment - train set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T17:07:45.672023Z",
     "iopub.status.busy": "2025-03-17T17:07:45.671711Z",
     "iopub.status.idle": "2025-03-17T17:09:30.546365Z",
     "shell.execute_reply": "2025-03-17T17:09:30.545297Z",
     "shell.execute_reply.started": "2025-03-17T17:07:45.672000Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "splits = [2, 3, 4, 5, 10] \n",
    "results = {metric: [] for metric in [\"accuracy\", \"roc_auc\", \"f1\", \"precision\", \"recall\"]}\n",
    "\n",
    "for n_splits in splits:\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    svm_model = SVC(kernel=\"linear\", probability=True, random_state=42)\n",
    "    metrics = {metric: [] for metric in results.keys()}\n",
    "\n",
    "    for train_idx, test_idx in cv.split(X_mel, y_mel):\n",
    "        X_train, X_test = np.array(X_mel)[train_idx], np.array(X_mel)[test_idx]\n",
    "        y_train, y_test = np.array(y_mel)[train_idx], np.array(y_mel)[test_idx]\n",
    "        \n",
    "        svm_model.fit(X_train, y_train)\n",
    "        y_pred = svm_model.predict(X_test)\n",
    "        y_proba = svm_model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        metrics[\"accuracy\"].append(accuracy_score(y_test, y_pred))\n",
    "        metrics[\"roc_auc\"].append(roc_auc_score(y_test, y_proba))\n",
    "        metrics[\"f1\"].append(f1_score(y_test, y_pred))\n",
    "        metrics[\"precision\"].append(precision_score(y_test, y_pred, zero_division=0))\n",
    "        metrics[\"recall\"].append(recall_score(y_test, y_pred))\n",
    "\n",
    "    for metric in metrics:\n",
    "        results[metric].append(np.mean(metrics[metric]))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for metric, values in results.items():\n",
    "    plt.plot(splits, values, marker=\"o\", label=metric.upper())\n",
    "\n",
    "plt.xlabel(\"Number of Splits (n_splits)\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"SVM Performance Across Different Train/Test Splits\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T17:09:30.547999Z",
     "iopub.status.busy": "2025-03-17T17:09:30.547708Z",
     "iopub.status.idle": "2025-03-17T17:09:33.313949Z",
     "shell.execute_reply": "2025-03-17T17:09:33.312823Z",
     "shell.execute_reply.started": "2025-03-17T17:09:30.547973Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "splits = [2, 3, 4, 5, 10] \n",
    "results = {metric: [] for metric in [\"accuracy\", \"roc_auc\", \"f1\", \"precision\", \"recall\"]}\n",
    "\n",
    "for n_splits in splits:\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    rf_model = RandomForestClassifier(n_estimators=45, max_depth=5, random_state=42)\n",
    "    metrics = {metric: [] for metric in results.keys()}\n",
    "\n",
    "    for train_idx, test_idx in cv.split(X_mel, y_mel):\n",
    "        X_train, X_test = np.array(X_mel)[train_idx], np.array(X_mel)[test_idx]\n",
    "        y_train, y_test = np.array(y_mel)[train_idx], np.array(y_mel)[test_idx]\n",
    "        \n",
    "        rf_model.fit(X_train, y_train)\n",
    "        y_pred = rf_model.predict(X_test)\n",
    "        y_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        metrics[\"accuracy\"].append(accuracy_score(y_test, y_pred))\n",
    "        metrics[\"roc_auc\"].append(roc_auc_score(y_test, y_proba))\n",
    "        metrics[\"f1\"].append(f1_score(y_test, y_pred))\n",
    "        metrics[\"precision\"].append(precision_score(y_test, y_pred, zero_division=0))\n",
    "        metrics[\"recall\"].append(recall_score(y_test, y_pred))\n",
    "\n",
    "    for metric in metrics:\n",
    "        results[metric].append(np.mean(metrics[metric]))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for metric, values in results.items():\n",
    "    plt.plot(splits, values, marker=\"o\", label=metric.upper())\n",
    "\n",
    "plt.xlabel(\"Number of Splits (n_splits)\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Random Forest Performance Across Different Train/Test Splits\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Experiment - imbalance processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T17:09:33.315713Z",
     "iopub.status.busy": "2025-03-17T17:09:33.315293Z",
     "iopub.status.idle": "2025-03-17T17:09:33.431497Z",
     "shell.execute_reply": "2025-03-17T17:09:33.430280Z",
     "shell.execute_reply.started": "2025-03-17T17:09:33.315675Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== SVM Cross-Validation Performance =====\n",
      "  ACCURACY: 0.492308 ± 0.029656\n",
      "  ROC_AUC: 0.464892 ± 0.045875\n",
      "  F1: 0.577384 ± 0.016706\n",
      "  PRECISION: 0.437347 ± 0.018216\n",
      "  RECALL: 0.850712 ± 0.023535\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "svm_model = SVC(kernel=\"linear\", probability=True, random_state=42, class_weight=\"balanced\", C=10)\n",
    "metrics = {\"accuracy\": [], \"roc_auc\": [], \"f1\": [],\"precision\": [], \"recall\": []}\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_zcr, y_zcr):\n",
    "    X_train, X_test = X_zcr[train_idx], X_zcr[test_idx]\n",
    "    y_train, y_test = y_zcr[train_idx], y_zcr[test_idx]\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    y_proba = svm_model.predict_proba(X_test)[:, 1]\n",
    "    metrics[\"accuracy\"].append(accuracy_score(y_test, y_pred))\n",
    "    metrics[\"roc_auc\"].append(roc_auc_score(y_test, y_proba))\n",
    "    metrics[\"f1\"].append(f1_score(y_test, y_pred))\n",
    "    metrics[\"precision\"].append(precision_score(y_test, y_pred, zero_division=0))\n",
    "    metrics[\"recall\"].append(recall_score(y_test, y_pred))\n",
    "\n",
    "svm_performance_zcr_balance = {metric: {\"mean\": np.mean(values), \"std\": np.std(values)} for metric, values in metrics.items()}\n",
    "print(\"===== SVM Cross-Validation Performance =====\")\n",
    "for metric, values in svm_performance_zcr_balance.items():\n",
    "    print(f\"  {metric.upper()}: {values['mean']:.6f} ± {values['std']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T17:09:33.432835Z",
     "iopub.status.busy": "2025-03-17T17:09:33.432511Z",
     "iopub.status.idle": "2025-03-17T17:09:33.678070Z",
     "shell.execute_reply": "2025-03-17T17:09:33.676991Z",
     "shell.execute_reply.started": "2025-03-17T17:09:33.432808Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "metrics = [\"accuracy\", \"roc_auc\", \"f1\", \"precision\", \"recall\"]\n",
    "features = [\"ZCR_pure\", \"ZCR_balanced\"]\n",
    "\n",
    "means = np.array([\n",
    "    [svm_performance_zcr[m][\"mean\"] for m in metrics],\n",
    "    [svm_performance_zcr_balance[m][\"mean\"] for m in metrics],\n",
    "])\n",
    "stds = np.array([\n",
    "    [svm_performance_zcr[m][\"std\"] for m in metrics],\n",
    "    [svm_performance_zcr_balance[m][\"std\"] for m in metrics],\n",
    "])\n",
    "\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.25\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for i in range(len(features)):\n",
    "    ax.bar(x + i * width, means[i], width, label=features[i], yerr=stds[i], capsize=5)\n",
    "\n",
    "ax.set_xlabel(\"Metrics\")\n",
    "ax.set_ylabel(\"Performance Score\")\n",
    "ax.set_title(\"Random Forest Performance Comparison Across Features\")\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "plt.ylim(0.0, 1.0) \n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T17:09:33.679184Z",
     "iopub.status.busy": "2025-03-17T17:09:33.678906Z",
     "iopub.status.idle": "2025-03-17T17:09:34.099363Z",
     "shell.execute_reply": "2025-03-17T17:09:34.098233Z",
     "shell.execute_reply.started": "2025-03-17T17:09:33.679148Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Balanced Random Forest Performance =====\n",
      "  ACCURACY: 0.598741 ± 0.033082\n",
      "  ROC_AUC: 0.655070 ± 0.016775\n",
      "  F1: 0.550488 ± 0.038670\n",
      "  PRECISION: 0.506520 ± 0.034639\n",
      "  RECALL: 0.604274 ± 0.051538\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rf_model = RandomForestClassifier( n_estimators=45, max_depth=5, class_weight=\"balanced\", random_state=42)\n",
    "metrics = {\"accuracy\": [], \"roc_auc\": [], \"f1\": [], \"precision\": [], \"recall\": []}\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_zcr, y_zcr):\n",
    "    X_train, X_test = np.array(X_zcr)[train_idx], np.array(X_zcr)[test_idx]\n",
    "    y_train, y_test = np.array(y_zcr)[train_idx], np.array(y_zcr)[test_idx]\n",
    "    \n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    y_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    metrics[\"accuracy\"].append(accuracy_score(y_test, y_pred))\n",
    "    metrics[\"roc_auc\"].append(roc_auc_score(y_test, y_proba))\n",
    "    metrics[\"f1\"].append(f1_score(y_test, y_pred))\n",
    "    metrics[\"precision\"].append(precision_score(y_test, y_pred, zero_division=0))\n",
    "    metrics[\"recall\"].append(recall_score(y_test, y_pred))\n",
    "\n",
    "rf_performance_zcr_balanced = {metric: {\"mean\": np.mean(values), \"std\": np.std(values)} for metric, values in metrics.items()}\n",
    "\n",
    "print(\"===== Balanced Random Forest Performance =====\")\n",
    "for metric, values in rf_performance_zcr_balanced.items():\n",
    "    print(f\"  {metric.upper()}: {values['mean']:.6f} ± {values['std']:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T17:09:34.100944Z",
     "iopub.status.busy": "2025-03-17T17:09:34.100465Z",
     "iopub.status.idle": "2025-03-17T17:09:34.374013Z",
     "shell.execute_reply": "2025-03-17T17:09:34.372752Z",
     "shell.execute_reply.started": "2025-03-17T17:09:34.100843Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "metrics = [\"accuracy\", \"roc_auc\", \"f1\", \"precision\", \"recall\"]\n",
    "features = [\"ZCR_pure\", \"ZCR_balanced\"]\n",
    "\n",
    "means = np.array([\n",
    "    [rf_performance_zcr[m][\"mean\"] for m in metrics],\n",
    "    [rf_performance_zcr_balanced[m][\"mean\"] for m in metrics],\n",
    "])\n",
    "stds = np.array([\n",
    "    [rf_performance_zcr[m][\"std\"] for m in metrics],\n",
    "    [rf_performance_zcr_balanced[m][\"std\"] for m in metrics],\n",
    "])\n",
    "\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.25\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for i in range(len(features)):\n",
    "    ax.bar(x + i * width, means[i], width, label=features[i], yerr=stds[i], capsize=5)\n",
    "\n",
    "ax.set_xlabel(\"Metrics\")\n",
    "ax.set_ylabel(\"Performance Score\")\n",
    "ax.set_title(\"Random Forest Performance Comparison Across Features\")\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "plt.ylim(0.0, 1.0) \n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Unsupervised learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T17:09:34.375609Z",
     "iopub.status.busy": "2025-03-17T17:09:34.375276Z",
     "iopub.status.idle": "2025-03-17T17:09:34.384327Z",
     "shell.execute_reply": "2025-03-17T17:09:34.382996Z",
     "shell.execute_reply.started": "2025-03-17T17:09:34.375583Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def kmeans_clustering_PCA(X, y, feature_name):\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42, n_init=5)\n",
    "    clusters = kmeans.fit_predict(X)\n",
    "    \n",
    "    acc1 = accuracy_score(y, clusters)\n",
    "    acc2 = accuracy_score(y, 1 - clusters)\n",
    "    best_acc = max(acc1, acc2)\n",
    "    print(f\"K-Means Clustering Accuracy ({feature_name}): {best_acc:.4f}\")\n",
    "    \n",
    "    #PCA Reduce dimensionality \n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    # Original labels\n",
    "    scatter1 = axes[0].scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap=\"viridis\", alpha=0.7)\n",
    "    axes[0].set_xlabel(\"PCA Original Component 1\")\n",
    "    axes[0].set_ylabel(\"PCA Original Component 2\")\n",
    "    axes[0].set_title(f\"Original Data Distribution ({feature_name})\")\n",
    "    fig.colorbar(scatter1, ax=axes[0], label=\"True Label\")\n",
    "\n",
    "    # K-Means clustering results\n",
    "    scatter2 = axes[1].scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap=\"coolwarm\", alpha=0.7)\n",
    "    axes[1].set_xlabel(\"PCA K-means Component 1\")\n",
    "    axes[1].set_ylabel(\"PCA K-means Component 2\")\n",
    "    axes[1].set_title(f\"K-Means Clustering ({feature_name})\")\n",
    "    fig.colorbar(scatter2, ax=axes[1], label=\"Cluster Label\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T17:09:34.386444Z",
     "iopub.status.busy": "2025-03-17T17:09:34.385677Z",
     "iopub.status.idle": "2025-03-17T17:09:34.416908Z",
     "shell.execute_reply": "2025-03-17T17:09:34.415766Z",
     "shell.execute_reply.started": "2025-03-17T17:09:34.386375Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def kmeans_clustering_ZCR(X, y):\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=2, random_state=42, n_init=5)\n",
    "    clusters = kmeans.fit_predict(X)\n",
    "\n",
    "    acc1 = accuracy_score(y, clusters)\n",
    "    acc2 = accuracy_score(y, 1 - clusters)\n",
    "    best_acc = max(acc1, acc2)\n",
    "    print(f\"K-Means Clustering Accuracy (ZCR): {best_acc:.4f}\")\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    axes[0].scatter(X, np.zeros_like(X), c=y, cmap=\"viridis\", alpha=0.7)\n",
    "    axes[0].set_xlabel(\"Zero-Crossing Rate (ZCR)\")\n",
    "    axes[0].set_yticks([]) \n",
    "    axes[0].set_title(\"Original Labels (ZCR)\")\n",
    "    \n",
    "    axes[1].scatter(X, np.zeros_like(X), c=clusters, cmap=\"coolwarm\", alpha=0.7)\n",
    "    axes[1].set_xlabel(\"Zero-Crossing Rate (ZCR)\")\n",
    "    axes[1].set_yticks([]) \n",
    "    axes[1].set_title(\"K-Means Clustering (ZCR)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T17:09:34.420921Z",
     "iopub.status.busy": "2025-03-17T17:09:34.420613Z",
     "iopub.status.idle": "2025-03-17T17:09:36.379485Z",
     "shell.execute_reply": "2025-03-17T17:09:36.378012Z",
     "shell.execute_reply.started": "2025-03-17T17:09:34.420898Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "acc_mfcc = kmeans_clustering_PCA(X_mfcc, y_mfcc, \"MFCC\")\n",
    "acc_mel = kmeans_clustering_PCA(X_mel, y_mel, \"Mel Spectrogram\")\n",
    "acc_zcr = kmeans_clustering_ZCR(X_zcr, y_zcr)\n",
    "print(\"\\nFinal Comparison of K-Means Clustering Accuracy:\")\n",
    "print(f\"MFCC Accuracy: {acc_mfcc:.4f}\")\n",
    "print(f\"Mel Spectrogram Accuracy: {acc_mel:.4f}\")\n",
    "print(f\"ZCR Accuracy: {acc_zcr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
